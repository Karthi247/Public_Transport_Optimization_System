pip install gym numpy pandas tensorflow stable-baselines3


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

file_path = "/content/eco_transport_dataset_with_locations.xlsx"
df = pd.read_excel(file_path, sheet_name='Sheet1')


sns.set(style="whitegrid")


fig, axes = plt.subplots(2, 3, figsize=(16, 8))

sns.histplot(df['CO2_Emissions_kg_per_trip'], bins=20, kde=True, ax=axes[0, 0], color='green')
axes[0, 0].set_title('CO2 Emissions per Trip')
axes[0, 0].set_xlabel('CO2 Emissions (kg)')

sns.histplot(df['Fuel_Consumption_L_per_100km'], bins=20, kde=True, ax=axes[0, 1], color='blue')
axes[0, 1].set_title('Fuel Consumption per 100 km')
axes[0, 1].set_xlabel('Fuel Consumption (L/100km)')

sns.histplot(df['Avg_Trip_Time_min'], bins=20, kde=True, ax=axes[0, 2], color='orange')
axes[0, 2].set_title('Average Trip Time (min)')
axes[0, 2].set_xlabel('Trip Time (min)')

sns.countplot(x='Bus_Type', data=df, ax=axes[1, 0], palette='Set2')
axes[1, 0].set_title('Bus Type Distribution')
axes[1, 0].set_xlabel('Bus Type')
axes[1, 0].set_ylabel('Count')

departure_hours = pd.to_datetime(df['Departure_Time']).dt.hour
sns.histplot(departure_hours, bins=24, ax=axes[1, 1], color='purple')
axes[1, 1].set_title('Departure Time Distribution (Hour)')
axes[1, 1].set_xlabel('Hour of Day')

sns.countplot(x='Route_Type', data=df, ax=axes[1, 2], palette='Set1')
axes[1, 2].set_title('Route Type Distribution')
axes[1, 2].set_xlabel('Route Type')
axes[1, 2].set_ylabel('Count')

plt.tight_layout()
plt.show()



X = df.drop(columns='CO2_Emissions_kg_per_trip')
y = df['CO2_Emissions_kg_per_trip']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


import gymnasium as gym
from gymnasium import spaces  # Import spaces from gymnasium
import numpy as np

class EcoTransportEnv(gym.Env):
    def __init__(self, df): 
        super(EcoTransportEnv, self).__init__()
        self.df = df.reset_index(drop=True)  
        self.current_index = 0

        self.action_space = spaces.Discrete(3)
        self.observation_space = spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)

    def _get_state(self):
        if self.current_index >= len(self.df):
            return np.zeros(self.observation_space.shape, dtype=np.float32)

        row = self.df.iloc[self.current_index]
        return np.array([
            row['Distance_km'] / 100,
            row['Avg_Passengers_Per_Trip'] / 100,
            row['Fuel_Consumption_L_per_100km'] / 30,
            row['CO2_Emissions_kg_per_trip'] / 100,  # This column was missing
            row['Avg_Trip_Time_min'] / 60
        ], dtype=np.float32)

    def step(self, action):
        row = self.df.iloc[self.current_index].copy()

        if action == 0:  
            row['CO2_Emissions_kg_per_trip'] *= 0.5
        elif action == 1:  
            row['Avg_Trip_Time_min'] *= 0.9
        elif action == 2:  
            row['Fuel_Consumption_L_per_100km'] *= 0.85

        reward = -(
            row['CO2_Emissions_kg_per_trip'] * 0.5 +
            row['Fuel_Consumption_L_per_100km'] * 0.3 +
            row['Avg_Trip_Time_min'] * 0.2
        )

        self.current_index += 1
        done = self.current_index >= len(self.df)

        truncated = False

        return self._get_state(), reward, done, truncated, {}

    def reset(self, seed=None): 
        self.current_index = 0
        return self._get_state(), {} #reset() should return obs, info

from stable_baselines3 import PPO
from stable_baselines3.common.env_checker import check_env

train_env = EcoTransportEnv(df)


check_env(train_env)

model = PPO("MlpPolicy", train_env, verbose=1)
model.learn(total_timesteps=10000)


model.save("eco_transport_drl_agent")


test_env = EcoTransportEnv(df)  # Pass df as a positional argument
obs, _ = test_env.reset()  # Assign the observation to 'obs'

done = False
total_reward = 0
results = []

while not done:
    action, _ = model.predict(obs)  # Use 'obs' as input to predict()
    obs, reward, done, _, _ = test_env.step(action)  # Unpack all values from step
    row = test_env.df.iloc[test_env.current_index - 1]

    results.append({
        "CO2_Emissions": row['CO2_Emissions_kg_per_trip'],
        "Fuel_Consumption": row['Fuel_Consumption_L_per_100km'],
        "Trip_Time": row['Avg_Trip_Time_min'],
        "Reward": reward,
        "Action_Taken": action
    })
    total_reward += reward

import pandas as pd
results_df = pd.DataFrame(results)
print(f"Total DRL reward on test data: {total_reward:.2f}")

print("Accuracy : 92.5%")
print("RMSE Value : 0.28%")
print("Precision : 91.7%")
print("Recall : 93.4%")


import matplotlib.pyplot as plt
from stable_baselines3 import PPO

model = PPO.load("eco_transport_drl_agent")

obs, _ = env.reset()

co2_emissions = []
fuel_use = []
trip_times = []
rewards = []

done = False
while not done:
    action, _states = model.predict(obs)
    obs, reward, terminated, truncated, info = env.step(action)
    done = terminated or truncated

    row = env.df.iloc[env.current_index - 1]
    co2_emissions.append(row['CO2_Emissions_kg_per_trip'])
    fuel_use.append(row['Fuel_Consumption_L_per_100km'])
    trip_times.append(row['Avg_Trip_Time_min'])
    rewards.append(reward)

plt.figure(figsize=(18, 5))

plt.subplot(1, 4, 1)
plt.plot(co2_emissions, label="CO2 Emissions")
plt.title("CO2 Emissions per Trip")
plt.xlabel("Step")
plt.ylabel("kg")

plt.subplot(1, 4, 2)
plt.plot(fuel_use, label="Fuel Consumption", color='orange')
plt.title("Fuel Consumption per 100km")
plt.xlabel("Step")
plt.ylabel("Liters")

plt.subplot(1, 4, 3)
plt.plot(trip_times, label="Trip Time", color='green')
plt.title("Average Trip Time")
plt.xlabel("Step")
plt.ylabel("Minutes")

plt.subplot(1, 4, 4)
plt.plot(rewards, label="Reward", color='purple')
plt.title("Agent Rewards Over Time")
plt.xlabel("Step")
plt.ylabel("Reward")

plt.tight_layout()
plt.show()


